{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2d6e409",
   "metadata": {},
   "source": [
    "The first step is to import some data. You data needs to be a list of dictionaries. Each dict needs to have a key named \"ref\" that corresponds to the path to your audio file, and \"sentence\" which is the transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de95725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data = []\n",
    "with open(\"data/metadata.csv\", \"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\",\", quotechar=\"|\")\n",
    "    for row in reader:\n",
    "        data.append({\"ref\" : row[0], \"sentence\" : row[1]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b721d37",
   "metadata": {},
   "source": [
    "Then you apply the PDM algorithm. The algorithm will take your list and compute the PDM scores between the audio and the sentence for all the elements. generating the phonetic transcription takes time but a checkpoint is regularly saved.\n",
    "The function returns the same list with an extra key for each dict named \"score\".\n",
    "The function also create a <lang_name>.pkl file that contains the phonetic transcriptions of your audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae6bfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/leferran/miniconda3/envs/main/lib/python3.8/site-packages/allosaurus/am/utils.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(str(path), map_location=torch.device('cpu'))\n",
      "100%|██████████| 10/10 [00:00<00:00, 1941.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from eval_align import phone_align\n",
    "\n",
    "phone_align(data,\"Seediq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce8abf7",
   "metadata": {},
   "source": [
    "Finally you can check the scores. In the example below, the 3 worse scores are for the examples for which half of the transription is missing of if the transcription in erroneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07bae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ini huwa, biqi ku   0.26415094339622647\n",
      " ceci est un texte en français ce qui n'est pas bien  0.2650602409638554\n",
      " this is a wrong transcription this is not right this is wrong  0.29357798165137616\n",
      " uxay nami musa meuyas patas pyasan ka sayang  0.36363636363636365\n",
      " ga bubu gakac ppuqan idu ka sari, ngali ma puqi naq  0.4897959183673469\n",
      " kesun msterung ita seediq ge, risu daha ka weewa msterung  0.5476190476190477\n",
      " wada rcuhan iyu mi slabu waliq emptsa ka lqihan mu  0.5742574257425743\n",
      " niqan quti rudux, sputu ma blebun, egu riyung klegan nana  0.6304347826086957\n",
      " uxay wana mtngi, pkmalu bi hiyi uri  0.631578947368421\n",
      " mkla bi smnru endaan ka tama rudan  0.6875\n"
     ]
    }
   ],
   "source": [
    "for ex in sorted(data, key=lambda x : x[\"score\"]):\n",
    "    print(ex[\"sentence\"], ex[\"score\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
